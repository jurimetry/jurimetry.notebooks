{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pickle import dump\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset and vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetByConnection:\n",
    "    def __init__(self, server='ec2-52-44-139-108.compute-1.amazonaws.com', db='ddhhqf3lrh36s1', us='', pw='', sql = None):\n",
    "        driver= '{PostgreSQL ODBC Driver(UNICODE)}'\n",
    "        self.Connection = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=5432;DATABASE='+db+';UID='+us+';PWD='+ pw+';sslmode=require;')\n",
    "        self.dbName = db\n",
    "        self.sql = sql\n",
    "        \n",
    "    def GetDataset(self):\n",
    "        if(self.sql==None):\n",
    "            self.sql = \"SELECT court_abreviation, decision_date, class, court_entry, court_decisor, court_session, court_sumary FROM public.jurisprudences;\"\n",
    "        \n",
    "        return pd.read_sql_query(self.sql, self.Connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFPrepare:\n",
    "    def __init__(self, server='', db='', us='', pw='', sql = None, yColumName='CourtSumary'):\n",
    "        self.server = server\n",
    "        self.db = db\n",
    "        self.us = us\n",
    "        self.pw = pw\n",
    "        self.sql = sql\n",
    "        self.yColumName = yColumName\n",
    "        \n",
    "    def create_clean_df(self):\n",
    "        dtc = DataSetByConnection(self.server, self.db, self.us, self.pw, sql=self.sql)\n",
    "        df = dtc.GetDataset()\n",
    "        print('\\r\\nQuery executada')\n",
    "        \n",
    "        df.columns = ['CourtAbreviation', 'Date', 'Class', 'CourtEntry', 'CourtDecisor', 'CourtSession', 'CourtSumary']\n",
    "        \n",
    "        df['Year'] = pd.to_datetime(df['Date'], format='%Y%m%d').dt.year\n",
    "        \n",
    "        df.drop(['Date'], axis='columns', inplace=True)\n",
    "\n",
    "        \n",
    "        df = self.vectorize(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def vectorize(self, df):\n",
    "        categorical_cols = [a for a in df.columns if a != 'Year']\n",
    "        \n",
    "        encoders = []\n",
    "        encoderNames = []\n",
    "        for x in categorical_cols:\n",
    "            le = None\n",
    "            le = LabelEncoder()\n",
    "                \n",
    "            le = le.fit(df[x])\n",
    "            df[x] = le.transform(df[x])\n",
    "            \n",
    "            encoderNames.append(x)\n",
    "            encoders.append(le)\n",
    "        \n",
    "        self.saveLe(encoders, encoderNames)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def saveLe(self, encoders, encoderNames):\n",
    "        foldername = \"label_encoders/\"+self.yColumName+\"/\"\n",
    "        if not os.path.exists(foldername):\n",
    "            os.makedirs(foldername)\n",
    "        \n",
    "        for encoder, name in zip(encoders, encoderNames):\n",
    "            filename = foldername+name+'.pkl'\n",
    "            #pickle.load(filename)\n",
    "            with open(filename, 'wb') as file:\n",
    "                dump(encoder, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset with \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"Naive Bayes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTraining:\n",
    "    def __init__(self, yColumName='CourtSumary', test_size=0.33, random_state=1000, server='', db='', us='', pw='', plot=False, sql = None):\n",
    "        self.yColumName = yColumName\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.x_test = None\n",
    "        self.y_teste = None\n",
    "        self.server = server\n",
    "        self.db = db\n",
    "        self.us = us\n",
    "        self.pw = pw\n",
    "        self.plot = plot\n",
    "        self.sql = sql\n",
    "        \n",
    "    def InitializeDatasets(self):\n",
    "        dPrepare = DFPrepare( \n",
    "                                server=self.server, \n",
    "                                db=self.db, \n",
    "                                us=self.us, \n",
    "                                pw=self.pw, \n",
    "                                sql=self.sql, \n",
    "                                yColumName=self.yColumName)\n",
    "\n",
    "        df = dPrepare.create_clean_df()\n",
    "        \n",
    "        x_cols = [a for a in df.columns if a != self.yColumName]\n",
    "        \n",
    "        print(self.yColumName)\n",
    "        \n",
    "        x = df[x_cols]\n",
    "        y = df[self.yColumName]\n",
    "\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size=self.test_size, random_state=self.random_state)\n",
    "    \n",
    "    \n",
    "    def training(self):\n",
    "        print('\\r\\nInicializando classificacao: '+self.yColumName)\n",
    "        print('\\r\\nInicializando dataset')\n",
    "        self.InitializeDatasets()\n",
    "        \n",
    "        names = [\"Nearest Neighbors\", #\"Linear SVM\", \"RBF SVM\", #\"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "        classifiers = [\n",
    "            KNeighborsClassifier(),\n",
    "            #SVC(kernel=\"linear\", C=0.025),\n",
    "            #SVC(gamma=2, C=1),\n",
    "            #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "            DecisionTreeClassifier(max_depth=5),\n",
    "            RandomForestClassifier(),\n",
    "            MLPClassifier(alpha=1, max_iter=1000),\n",
    "            AdaBoostClassifier(),\n",
    "            GaussianNB()]\n",
    "        \n",
    "        if(self.plot):\n",
    "            figure = plt.figure(figsize=(27, 9))\n",
    "        \n",
    "        print('\\r\\nClassficando dados tratados\\r\\n')\n",
    "        for name, clf in zip(names, classifiers):\n",
    "            self.Classify(name, clf)\n",
    "    \n",
    "    def Classify(self, name, classifier):\n",
    "        print('\\r\\nIniciado treinamento: '+name+'\\r\\n')\n",
    "        classifier.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        print('\\r\\nVerificando Score: '+name+'\\r\\n')\n",
    "        score = classifier.score(self.x_test, self.y_test)\n",
    "        \n",
    "        print('\\r\\nSalvando modelo: '+name+'\\r\\n')\n",
    "        self.save(name, score*100, classifier)\n",
    "        \n",
    "        title = name + ' score: ' + str(score*100) + '%'\n",
    "        \n",
    "        if(self.plot):\n",
    "            print('\\r\\nIniciando plot de graficos: '+name+'\\r\\n')\n",
    "            self.plotG(title, classifier)\n",
    "        else:\n",
    "            print(title)\n",
    "        \n",
    "    def plotG(self, title, classifier):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.title.set_text(title)\n",
    "        ax.scatter(self.y_test, classifier.predict(self.x_test), edgecolors=(0, 0, 0))\n",
    "        ax.plot([self.y_test.min(), self.y_test.max()], [self.y_test.min(), self.y_test.max()], 'k--', lw=4)\n",
    "        ax.set_xlabel('Measured')\n",
    "        ax.set_ylabel('Predicted')\n",
    "        plt.show()\n",
    "    \n",
    "    def save(self, name, score, classifier):\n",
    "        # save the model to disk\n",
    "        foldername = \"models_save/\"+self.yColumName+\"/\"\n",
    "        if not os.path.exists(foldername):\n",
    "            os.makedirs(foldername)\n",
    "        #else:\n",
    "            #shutil.rmtree(foldername)\n",
    "           # os.makedirs(foldername)\n",
    "            \n",
    "        filename = foldername+name+'_'+str(int(score))+'_finalized_model.sav'\n",
    "        joblib.dump(classifier, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variaveis para utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_size= 0.25\n",
    "Server='ec2-52-44-139-108.compute-1.amazonaws.com'\n",
    "Db='ddhhqf3lrh36s1'\n",
    "Us='gskutxpzrujbls'\n",
    "Pw='74ae60662e5109135465d0bd124188a54cfbebe2efd4077885692c6efd1b324d'\n",
    "Plot=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando natureza a partir do banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "YColumName= 'CourtSumary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DataTraining(\n",
    "                    test_size= Test_size, \n",
    "                    server=Server, \n",
    "                    db=Db, \n",
    "                    us=Us, \n",
    "                    pw=Pw, \n",
    "                    plot=Plot,\n",
    "                    yColumName= YColumName\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inicializando classificacao: CourtSumary\n",
      "\n",
      "Inicializando dataset\n",
      "\n",
      "Query executada\n",
      "CourtSumary\n",
      "\n",
      "Classficando dados tratados\n",
      "\n",
      "\n",
      "Iniciado treinamento: Nearest Neighbors\n",
      "\n",
      "\n",
      "Verificando Score: Nearest Neighbors\n",
      "\n",
      "\n",
      "Salvando modelo: Nearest Neighbors\n",
      "\n",
      "Nearest Neighbors score: 61.45086461408689%\n",
      "\n",
      "Iniciado treinamento: Decision Tree\n",
      "\n",
      "\n",
      "Verificando Score: Decision Tree\n",
      "\n",
      "\n",
      "Salvando modelo: Decision Tree\n",
      "\n",
      "Decision Tree score: 63.39097427245888%\n",
      "\n",
      "Iniciado treinamento: Random Forest\n",
      "\n",
      "\n",
      "Verificando Score: Random Forest\n",
      "\n",
      "\n",
      "Salvando modelo: Random Forest\n",
      "\n",
      "Random Forest score: 65.75284690004217%\n",
      "\n",
      "Iniciado treinamento: Neural Net\n",
      "\n",
      "\n",
      "Verificando Score: Neural Net\n",
      "\n",
      "\n",
      "Salvando modelo: Neural Net\n",
      "\n",
      "Neural Net score: 61.87262758329819%\n",
      "\n",
      "Iniciado treinamento: AdaBoost\n",
      "\n",
      "\n",
      "Verificando Score: AdaBoost\n",
      "\n",
      "\n",
      "Salvando modelo: AdaBoost\n",
      "\n",
      "AdaBoost score: 59.46857865879376%\n",
      "\n",
      "Iniciado treinamento: Naive Bayes\n",
      "\n",
      "\n",
      "Verificando Score: Naive Bayes\n",
      "\n",
      "\n",
      "Salvando modelo: Naive Bayes\n",
      "\n",
      "Naive Bayes score: 60.2277520033741%\n"
     ]
    }
   ],
   "source": [
    "dt.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
